# ID2223Lab1
### Iris
To run the iris (and wine) notebooks I used the docker all-spark jupyter nootebook docker image for python 3.10 (I installed hopsworks from within the notebook). I ran the "daily" feature and inference pipelines 4 times a day (in order to have a slightly faster dataflow and see if it worked correctly quicker) using github actions instead of modal. The two apps were run on hugggingface gradio spaces, I had too change the requirements
to include httpx==0.24.1 but appart from that I simply had to copy from the example code.

### Wine
#### wine-eda-and-backfill-feature-group.ipynb
This notebook is very similar to the Iris example. I first read the data and stored it in a pandas dataframe. I noticed that although many columns were missing some values no column was missing a lot. As such I chose to simply remove the rows were at least one value was missing. This removed roughly 30 out of 6500 row, aka neglible. I then drew paiplots and violinplots to roughly see what features were contributing to the quality and how. As it turned out the dataset was very evenly distributed across all qualities for all nearly all features with most features only having minor differences in mean and deviation. As such I chose to keep all features except for fixed acidity (which I deemed to be too closely distributed to add anything significant to the model) and let the model have as much data as possible to train with.

#### wine-training-pipeline.ipynb
As mentioned above I used all features except for fixed acidity in the feature view to create the training data. After testing a few models I settled on a scikit learn histogram gradient boosting classifier (HistGradientBoostingClassifier) with l2_regularization=3, max_iter=75 and learning rate=0.2. This model achieved an accuracy of 58\% which I considered good enough. In comparison a vanila K nearest neighbour model had an accuracy of roughly 36% and puerely guessing would have an accuracy 14%. Once the model was trained I saved it on hopsworks model registry togheter with the confusion matrix on the test data. The model is not very good at catching the outliers which there are few instances of e.g. 3, 4, 8 and 9, this is because the model was trained with equal weight on all labels prioritising getting as many correct as possible instead of finding high quality wine.

##### Gradio app
It it the same as the iris app but displays the result with a label instead of an image. The default values where set as the avereage values of for each parameter.

### wine-feature-pipeline-daily.py
Essentially the same as the iris program but with wine instead. The main difference is how the new wine is generated. The iris was generated by drawing from a uniform distribution for each parameter and class. I instead chose to generate the new sample by first choosing a type (white or red) uniformly and then choosing a quailty based on a normal distribution (since that is roughly how it was distributed). After randomly choosing a type and quality I downloaded the data from hopsworks and cut out all row which did not fit my quality and type. With this dataframe I then calculated the mean and standard deviation for the sample I wanted to add. Finally I drew the new data point with features drawn from a normal distribution according to the average already present in the ddata set. This way I better captured the characteristics of the data compared to simply drawing features from uniform distributions.

### wine-batch-inference-pipeline.py
Same as for Irirs with the main difference being that I save the predictions and actual quality as textfiles instead of images as in Irirs.
